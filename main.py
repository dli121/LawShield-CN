import uvicorn
from fastapi import FastAPI
from pydantic import BaseModel
from src.core.policy_engine import engine

# --- New: å¼•å…¥åˆšåˆšå†™çš„ LLM å®¢æˆ·ç«¯ ---
from src.core.llm import llm_client

app = FastAPI(
    title="LawShield-CN Enterprise Gateway",
    description="ç­–ç•¥é©±åŠ¨çš„ä¸­å›½æ³•å¾‹åˆè§„ AI ç½‘å…³",
    version="0.1.0",
)


class ChatRequest(BaseModel):
    query: str
    user_id: str = "anonymous"


class ChatResponse(BaseModel):
    response: str
    is_blocked: bool = False
    blocked_reason: str = None
    legal_ref: str = None


@app.post("/v1/chat/completions", response_model=ChatResponse)
async def chat_endpoint(request: ChatRequest):
    user_query = request.query

    # --- 1. Input Guard (è¾“å…¥æ‹¦æˆª) ---
    is_blocked, msg, ref = engine.check_input(user_query)
    if is_blocked:
        return ChatResponse(
            response=msg,
            is_blocked=True,
            blocked_reason="policy_violation",
            legal_ref=ref,
        )

    # --- 2. LLM Call (çœŸå®è°ƒç”¨) ---
    print(f"ğŸ¤– [ç½‘å…³è½¬å‘] æ­£åœ¨è¯·æ±‚å¤§æ¨¡å‹: {user_query}")
    ai_response = llm_client.chat(user_query)

    # --- 3. Output Guard (ç®€å•è¾“å‡ºå®¡è®¡ - Day 3 æ–°å¢) ---
    # ç®€å•çš„å…³é”®è¯æ£€æŸ¥ï¼Œé˜²æ­¢ AI è¯´å‡ºâ€œæˆ‘ä¸ç¡®å®šâ€è¿™ç§ä¸ä¸“ä¸šçš„è¯ï¼ˆæ¼”ç¤ºç”¨ï¼‰
    if "æˆ‘ä¸ç¡®å®š" in ai_response:
        ai_response += "\n\n(ç³»ç»Ÿæç¤ºï¼šAIå›ç­”ä»…ä¾›å‚è€ƒï¼Œå…·ä½“è¯·å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆã€‚)"

    return ChatResponse(response=ai_response)


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
